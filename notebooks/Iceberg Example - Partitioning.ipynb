{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b509b648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.9/site-packages (2.9.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: faker in /usr/local/lib/python3.9/site-packages (13.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "### Basic Dependency stuff.\n",
    "import sys\n",
    "!pip install --prefix {sys.prefix} psycopg2 pandas faker\n",
    "\n",
    "import psycopg2\n",
    "import time\n",
    "import sys, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b3d7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining a few SQL Statements, including a partitioned SQL table\n",
    "\n",
    "drop_if_exists = \"\"\"DROP TABLE  IF EXISTS public.employee\"\"\"\n",
    "\n",
    "employee_ddl = \"\"\"CREATE TABLE public.employee (\n",
    "    id int8 NOT NULL,\n",
    "    name varchar(120) NOT NULL,\n",
    "    salary int8 NOT NULL\n",
    ") PARTITION BY RANGE (salary);\n",
    "\n",
    "CREATE TABLE public.employee_to_1500 PARTITION OF public.employee\n",
    "    FOR VALUES FROM (0) TO (1500);\n",
    "    \n",
    "CREATE TABLE public.employee_to_3000 PARTITION OF public.employee\n",
    "    FOR VALUES FROM (1500) TO (3000);\n",
    "    \n",
    "CREATE TABLE public.employee_to_6000 PARTITION OF public.employee\n",
    "    FOR VALUES FROM (3000) TO (6000);\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sql_dummy_data = \"\"\"WITH salary_list AS (\n",
    "    SELECT '{1000, 2000, 5000}'::INT[] salary\n",
    ")\n",
    "INSERT INTO public.employee\n",
    "(id, name, salary)\n",
    "SELECT n, 'Employee ' || n as name, salary[1 + mod(n, array_length(salary, 1))]\n",
    "FROM salary_list, generate_series(1, 10000) as n\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "476d7819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 'Employee 3', 1000), (6, 'Employee 6', 1000), (9, 'Employee 9', 1000), (12, 'Employee 12', 1000), (15, 'Employee 15', 1000), (18, 'Employee 18', 1000), (21, 'Employee 21', 1000), (24, 'Employee 24', 1000), (27, 'Employee 27', 1000), (30, 'Employee 30', 1000)]\n",
      "[(2, 'Employee 2', 5000), (5, 'Employee 5', 5000), (8, 'Employee 8', 5000), (11, 'Employee 11', 5000), (14, 'Employee 14', 5000), (17, 'Employee 17', 5000), (20, 'Employee 20', 5000), (23, 'Employee 23', 5000), (26, 'Employee 26', 5000), (29, 'Employee 29', 5000)]\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(host=\"postgres\", port = 5432, database=\"demo_catalog\", user=\"admin\", password=\"password\")\n",
    "cur = conn.cursor()\n",
    "  \n",
    "############--------#--------#--------#--------#--------#--------#--------#--------#--------#--------#--------#-----\n",
    "## Delete possible old table, create the new one, add a bunch of columns, get ready!\n",
    "\n",
    "cur.execute(drop_if_exists)\n",
    "cur.execute(employee_ddl)\n",
    "cur.execute(sql_dummy_data)\n",
    "\n",
    "cur.execute(f\"\"\"SELECT * FROM public.employee LIMIT 10\"\"\")\n",
    "print(cur.fetchall())\n",
    "cur.execute(f\"\"\"SELECT * FROM public.employee_to_6000 LIMIT 10\"\"\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e1682",
   "metadata": {},
   "source": [
    "**Task**: So what happens, if we insert something with a larger salary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46aba909",
   "metadata": {},
   "outputs": [
    {
     "ename": "InFailedSqlTransaction",
     "evalue": "current transaction is aborted, commands ignored until end of transaction block\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInFailedSqlTransaction\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sql_dummy_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mINSERT INTO public.employee\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m(id, name, salary) VALUES (1, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrich_bob\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, 7000)\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_dummy_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInFailedSqlTransaction\u001b[0m: current transaction is aborted, commands ignored until end of transaction block\n"
     ]
    }
   ],
   "source": [
    "sql_dummy_data = \"\"\"INSERT INTO public.employee\n",
    "(id, name, salary) VALUES (1, 'rich_bob', 7000)\"\"\"\n",
    "cur.execute(sql_dummy_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a79a61",
   "metadata": {},
   "source": [
    "That's not cool right? The problem is, **partitioning** is for some reason I haven't figured out, in almost all tools \n",
    "like Postgres and other object stores which are topped of with Hive something almost completely\n",
    "manual. Just think about the next task..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33e074",
   "metadata": {},
   "source": [
    "**Task**: So let's change the partition key because right now we realize the salary is all in the latter bucket, \n",
    "we might from now on want to partition by employee name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072fa077",
   "metadata": {},
   "source": [
    "**How does that work in PostgreSQL?** Mostly by hand and rewriting the old partitions. You could hack around it\n",
    "and create \"new partitions just for newly inserted data\" by using triggers on read & write, but it involves\n",
    "quite a bit of manual effort. \n",
    "\n",
    "\n",
    "**Using Hive**: If you're using most object stores with just Hive on top, you'll need to migrate the data and rewrite \n",
    "the old data sets into new partitions (or as explained, do some manual workarounds based on insert time). \n",
    "=> No Fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0502ad",
   "metadata": {},
   "source": [
    "### Partition Changes in Iceberg: Hidden Magic ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b33dc7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-iceberg:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f372f1e1a00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9796e90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS nyc.employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1fff854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_ddl = \"\"\"CREATE TABLE nyc.employee (\n",
    "    id int,\n",
    "    name varchar(120),\n",
    "    salary int\n",
    ") PARTITIONED BY (truncate(1500,salary));\"\"\" ## using a partition transform function to create partitions \n",
    "## just as above where each bucket has salaries of \"width 1500\" => high-low = 1500 roughly.\n",
    "\n",
    "spark.sql(employee_ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b93b6f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>partition</th>\n",
       "            <th>record_count</th>\n",
       "            <th>file_count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----------+--------------+------------+\n",
       "| partition | record_count | file_count |\n",
       "+-----------+--------------+------------+\n",
       "+-----------+--------------+------------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM nyc.employee.partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2982049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1001 data rows to insert\n",
      "data is of size: 0.086484375 MB \n",
      "+---+-----+------+\n",
      "|id |name |salary|\n",
      "+---+-----+------+\n",
      "|1  |Bob  |1200  |\n",
      "|2  |Bob0 |0     |\n",
      "|2  |Bob1 |7     |\n",
      "|2  |Bob2 |14    |\n",
      "|2  |Bob3 |21    |\n",
      "|2  |Bob4 |28    |\n",
      "|2  |Bob5 |35    |\n",
      "|2  |Bob6 |42    |\n",
      "|2  |Bob7 |49    |\n",
      "|2  |Bob8 |56    |\n",
      "|2  |Bob9 |63    |\n",
      "|2  |Bob10|70    |\n",
      "|2  |Bob11|77    |\n",
      "|2  |Bob12|84    |\n",
      "|2  |Bob13|91    |\n",
      "|2  |Bob14|98    |\n",
      "|2  |Bob15|105   |\n",
      "|2  |Bob16|112   |\n",
      "|2  |Bob17|119   |\n",
      "|2  |Bob18|126   |\n",
      "+---+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############--------#--------#--------#--------#--------#--------#--------#--------#--------#--------#--------#-----\n",
    "## Some preparation data & SQLs\n",
    "\n",
    "data = [(1, \"Bob\",1200)]\n",
    "for i in range(0,1000):\n",
    "    data.append((2,f\"Bob{i}\",i*7))\n",
    "print(f\"Created {len(data)} data rows to insert\")\n",
    "\n",
    "print(f\"data is of size: {sys.getsizeof(data)/102400} MB \")\n",
    "rdd = spark.sparkContext.parallelize(data, numSlices=math.ceil(sys.getsizeof(data) / 102400))\n",
    "\n",
    "df = rdd.toDF()\n",
    "columns = [\"id\",\"name\",\"salary\"]\n",
    "df = rdd.toDF(columns)\n",
    "df.write.mode(\"append\").saveAsTable(\"nyc.employee\")\n",
    "# write takes about 25 secs and is 10 times the size of the other write... \n",
    "\n",
    "\n",
    "spark.read.format(\"iceberg\").load(\"nyc.employee\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef599b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6892e256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>partition</th>\n",
       "            <th>record_count</th>\n",
       "            <th>file_count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=3000)</td>\n",
       "            <td>214</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=1500)</td>\n",
       "            <td>214</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0)</td>\n",
       "            <td>216</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=6000)</td>\n",
       "            <td>142</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=4500)</td>\n",
       "            <td>215</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+------------------------+--------------+------------+\n",
       "|              partition | record_count | file_count |\n",
       "+------------------------+--------------+------------+\n",
       "| Row(salary_trunc=3000) |          214 |          1 |\n",
       "| Row(salary_trunc=1500) |          214 |          1 |\n",
       "|    Row(salary_trunc=0) |          216 |          1 |\n",
       "| Row(salary_trunc=6000) |          142 |          1 |\n",
       "| Row(salary_trunc=4500) |          215 |          1 |\n",
       "+------------------------+--------------+------------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM nyc.employee.partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21c8bf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "INSERT INTO nyc.employee\n",
    "(id, name, salary) VALUES (1, 'rich_bob', 7000)\n",
    "\n",
    "/* works like a charm */"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4cddb7",
   "metadata": {},
   "source": [
    "**Task**: Changing the partition, as you might imagine, is just as easy in iceberg. Let's do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6da9cfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.employee ADD PARTITION FIELD truncate(4,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea956ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 101 data rows to insert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 19:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "############--------#--------#--------#--------#--------#--------#--------#--------#--------#--------#--------#-----\n",
    "## Some preparation data & SQLs\n",
    "\n",
    "data = [(1, \"Bob\",1200)]\n",
    "for i in range(0,100):\n",
    "    data.append((2,f\"Bob{i}\",i*7))\n",
    "print(f\"Created {len(data)} data rows to insert\")\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(data, numSlices=1)\n",
    "\n",
    "df = rdd.toDF()\n",
    "columns = [\"id\",\"name\",\"salary\"]\n",
    "df = rdd.toDF(columns)\n",
    "df.write.mode(\"append\").saveAsTable(\"nyc.employee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c5f20cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>partition</th>\n",
       "            <th>record_count</th>\n",
       "            <th>file_count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=6000, name_trunc_4=None)</td>\n",
       "            <td>144</td>\n",
       "            <td>3</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=&#x27;Bob0&#x27;)</td>\n",
       "            <td>1</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=4500, name_trunc_4=None)</td>\n",
       "            <td>215</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=&#x27;Bob&#x27;)</td>\n",
       "            <td>1</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=&#x27;Bob4&#x27;)</td>\n",
       "            <td>11</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=&#x27;Bob3&#x27;)</td>\n",
       "            <td>11</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=&#x27;Bob2&#x27;)</td>\n",
       "            <td>11</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=&#x27;Bob1&#x27;)</td>\n",
       "            <td>11</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=&#x27;Bob8&#x27;)</td>\n",
       "            <td>11</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=&#x27;Bob7&#x27;)</td>\n",
       "            <td>11</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=&#x27;Bob6&#x27;)</td>\n",
       "            <td>11</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=&#x27;Bob5&#x27;)</td>\n",
       "            <td>11</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=1500, name_trunc_4=None)</td>\n",
       "            <td>214</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=&#x27;Bob9&#x27;)</td>\n",
       "            <td>11</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=3000, name_trunc_4=None)</td>\n",
       "            <td>214</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Row(salary_trunc=0, name_trunc_4=None)</td>\n",
       "            <td>216</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------------------------------------------+--------------+------------+\n",
       "|                                 partition | record_count | file_count |\n",
       "+-------------------------------------------+--------------+------------+\n",
       "| Row(salary_trunc=6000, name_trunc_4=None) |          144 |          3 |\n",
       "|  Row(salary_trunc=0, name_trunc_4='Bob0') |            1 |          1 |\n",
       "| Row(salary_trunc=4500, name_trunc_4=None) |          215 |          1 |\n",
       "|   Row(salary_trunc=0, name_trunc_4='Bob') |            1 |          1 |\n",
       "|  Row(salary_trunc=0, name_trunc_4='Bob4') |           11 |          1 |\n",
       "|  Row(salary_trunc=0, name_trunc_4='Bob3') |           11 |          1 |\n",
       "|  Row(salary_trunc=0, name_trunc_4='Bob2') |           11 |          1 |\n",
       "|  Row(salary_trunc=0, name_trunc_4='Bob1') |           11 |          1 |\n",
       "|  Row(salary_trunc=0, name_trunc_4='Bob8') |           11 |          1 |\n",
       "|  Row(salary_trunc=0, name_trunc_4='Bob7') |           11 |          1 |\n",
       "|  Row(salary_trunc=0, name_trunc_4='Bob6') |           11 |          1 |\n",
       "|  Row(salary_trunc=0, name_trunc_4='Bob5') |           11 |          1 |\n",
       "| Row(salary_trunc=1500, name_trunc_4=None) |          214 |          1 |\n",
       "|  Row(salary_trunc=0, name_trunc_4='Bob9') |           11 |          1 |\n",
       "| Row(salary_trunc=3000, name_trunc_4=None) |          214 |          1 |\n",
       "|    Row(salary_trunc=0, name_trunc_4=None) |          216 |          1 |\n",
       "+-------------------------------------------+--------------+------------+"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM nyc.employee.partitions\n",
    "/* We still got old partitions with name_trunc_4 set to None, but we \n",
    "\n",
    "*/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
